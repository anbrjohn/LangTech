# LangTech

Files for Language Technology I at Universität Saarlandes, 2016-2017

LSTM Twitterbot
------

**"Ere the hour of the twattering of bards in the twitterlitter"
-Finnegan's Wake**

https://twitter.com/james_joyce_bot
"LeopoldBloomFilter"

Trains a character-based neural network with Long Short-Term 
Memory on the collective works of James Joyce (0.6 million tokens).
Generates sample tweets and automatically posts them to
twitter at 10 minute intervals.

The model consists of a LSTM layer of 256 neurons, followed by 2 dense hidden layers of
100 neurons each. Dropout is 0.2 and the activation function is ReLU, except for the final
activation function, which is softmax. The optimizer used was adam. The training batch size
was 128 and due to restrictions in time/processing power, it was trained over only 50 epochs.
The model is character-based with a sequence length of 5 as the input.

Joyce’s prose often has a rhythmic, sing-song quality. Although semantically incoherent, some
of the generated tweets seem to reproduce this. Note the assonance in:
"black the born the stor of the said. Hore of her, a believe the be and sorare off
the satise tir they was of the"


Neural Classifier
------

Generates clusters of random points with a Gaussian distribution belonging
to one of two labels (red or blue), such that they cannot be classified
by a linear classifier. Using keras, creates a feedforward neural network
that classifies them with high accuracy.

Architecture: (*Image generated using https://gist.github.com/anbrjohn/7116fa0b59248375cd0c0371d6107a59)

![My image](https://github.com/anbrjohn/LangTech/blob/master/FFNNarchitecture.png)



Random point clusters:

![My image](https://github.com/anbrjohn/LangTech/blob/master/pointclusters.png)

Approximation of model generated by neural network:

![My image](https://github.com/anbrjohn/LangTech/blob/master/classifier.png)

Perceptron
------

Not coded by me. Annotations added by me as assignment.
